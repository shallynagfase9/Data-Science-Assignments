{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCZssQyBHUNQx8q9k0LiNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Data-Science-Assignments/blob/main/Logistic_Regression_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
      ],
      "metadata": {
        "id": "zavWHUQd88Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The purpose of Grid Search with Cross-Validation (Grid Search CV) in machine learning is to systematically search for the best hyperparameters for a given model.\n",
        "Hyperparameters are the parameters that are not learned from the data but are set prior to the training process, such as the regularization strength in logistic regression, the depth of a decision tree, or the learning rate in gradient boosting.\n",
        "Grid Search CV helps in finding the optimal combination of these hyperparameters to maximize the modelâ€™s performance.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "G6337Cyj881R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
        "one over the other?"
      ],
      "metadata": {
        "id": "JELjoFQ889QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Grid Search CV is best for small, discrete hyperparameter spaces where an exhaustive search is feasible. Randomized Search CV is more efficient and scalable for larger or continuous hyperparameter spaces, making it a good choice when resources are limited or a faster approximate solution is acceptable.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SMQgiuG_8-nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
      ],
      "metadata": {
        "id": "OSrcCcwx8-2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data leakage occurs when information from outside the training dataset is inadvertently used to create the model. This results in overly optimistic performance estimates during training and validation, leading to models that fail to generalize well to new, unseen data.\n",
        "Preventing data leakage involves careful feature selection, proper data splitting, using pipelines, and applying domain knowledge to ensure that only appropriate information is used during model training and validation.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ViYmruOs9Agb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How can you prevent data leakage when building a machine learning model?"
      ],
      "metadata": {
        "id": "-vBiIfeX9Awq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preventing data leakage involves careful feature selection, proper data splitting, using pipelines, and applying domain knowledge to ensure that only appropriate information is used during model training and validation.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "H_Du0wnL9CKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
      ],
      "metadata": {
        "id": "ba6LGKBY9CZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "A confusion matrix is a table that allows visualization of the performance of a classification model. It is particularly useful for summarizing the results of a binary (two-class) classification problem but can also be extended to multiclass problems.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sY9R7da99EH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Explain the difference between precision and recall in the context of a confusion matrix."
      ],
      "metadata": {
        "id": "JlhZ7np29Egs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Precision focuses on the accuracy of positive predictions, aiming to minimize false positives.\n",
        "Recall focuses on the ability to correctly identify positive instances, aiming to minimize false negatives.\n",
        "Together, precision and recall provide a balanced view of a model's performance in terms of positive predictions and identification of positive instances, each catering to different priorities in different applications.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_MlJjBoa9KoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
      ],
      "metadata": {
        "id": "6q87wYd09LGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Interpreting a confusion matrix involves analyzing the distribution of correct and incorrect predictions across different classes.\n",
        "This analysis helps in understanding where the model excels and where it struggles, guiding adjustments in model parameters (e.g., thresholds) or feature engineering to improve overall performance.\n",
        "By focusing on specific types of errors (FP, FN), you can tailor your approach to optimize the model's behavior based on the specific requirements and constraints of your application.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MSc00e0C9NGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
        "calculated?"
      ],
      "metadata": {
        "id": "sMx5glAI9NcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. Accuracy\n",
        "Accuracy measures the proportion of correctly classified instances out of the total instances.\n",
        "\n",
        "2. Precision\n",
        "Precision measures the accuracy of positive predictions. It indicates the proportion of positive predictions that were actually correct.\n",
        "\n",
        "3. Recall (Sensitivity or True Positive Rate)\n",
        "Recall measures the ability of the model to correctly identify positive instances. It indicates the proportion of actual positives that were correctly predicted by the model.\n",
        "\n",
        "4. Specificity (True Negative Rate)\n",
        "Specificity measures the ability of the model to correctly identify negative instances. It indicates the proportion of actual negatives that were correctly predicted by the model.\n",
        "\n",
        "5. F1-Score\n",
        "F1-Score is the harmonic mean of precision and recall. It provides a balance between precision and recall, making it a useful metric when there is an uneven class distribution.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "E43SDoSJ9PcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
      ],
      "metadata": {
        "id": "N-wvUiJW9Pwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The accuracy of a model is directly related to the values in its confusion matrix because accuracy is a function of correctly classified instances (TP and TN) relative to the total number of instances.\n",
        "Understanding the distribution of these values within the confusion matrix helps diagnose where the model excels and where it struggles, providing insights into potential areas for improvement or optimization.\n",
        "Therefore, the confusion matrix serves as a foundational tool in assessing and interpreting the overall performance of a classification model.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7ng4iIZT9Rg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
        "model?"
      ],
      "metadata": {
        "id": "QQhE6Tdz9SHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Potential Biases or Limitations Identified:\n",
        "- Class Imbalance: There are more instances in the \"Rejected\" class compared to the \"Approved\" class, which might bias the model towards predicting rejections more conservatively.\n",
        "- Misclassification Patterns: The model has a higher number of false negatives (100 FN) compared to false positives (50 FP) for the \"Approved\" class, indicating potential bias against approving applicants who should have been approved.\n",
        "- Sensitivity to Data Quality: If certain applicants are consistently misclassified due to missing or incorrect data, it could highlight limitations in data preprocessing or feature engineering.\n",
        "- Fairness Consideration: Assess whether errors disproportionately affect certain demographics (e.g., gender or ethnicity), which could indicate biases that need to be addressed for fair decision-making.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bPmQglMs9TwF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}