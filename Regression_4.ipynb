{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtKCIJY2N0Kt7sOuGQ/O4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Data-Science-Assignments/blob/main/Regression_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
      ],
      "metadata": {
        "id": "wYCBjAzd_77E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Lasso Regression, or Least Absolute Shrinkage and Selection Operator Regression, is a regression technique used to perform variable selection and regularization to improve the prediction accuracy and interpretability of the statistical model.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Rj5YuxcU_-QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the main advantage of using Lasso Regression in feature selection?"
      ],
      "metadata": {
        "id": "kZMtF8s7_-g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Advantage of Lasso Regression in Feature Selection:\n",
        "- Automatic Variable Selection\n",
        "- Handles Multicollinearity\n",
        "- Improved Model Performance\n",
        "- Feature Interpretability\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XYqz0ciAAAUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How do you interpret the coefficients of a Lasso Regression model?"
      ],
      "metadata": {
        "id": "V2JvM9NIAAsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Interpreting the coefficients of a Lasso Regression model involves understanding how the regularization affects the estimated coefficients and their relationship to the target variable.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pzvd5P7EAClE",
        "outputId": "c7facc60-661b-463e-963b-a594c91e7628"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nInterpreting the coefficients of a Lasso Regression model involves understanding how the regularization affects the estimated coefficients and their relationship to the target variable. \\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
        "model's performance?"
      ],
      "metadata": {
        "id": "_YxZR51OADEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "In Lasso Regression, there are mainly two tuning parameters that can be adjusted to control the model's performance:\n",
        "\n",
        "- Regularization Parameter (位):\n",
        "\n",
        "Definition: 位 (lambda) controls the strength of regularization applied in Lasso Regression. It balances between fitting the model to the training data and keeping the model coefficients small to avoid overfitting.\n",
        "\n",
        "Impact on Model Performance:\n",
        "Increasing 位 increases the amount of shrinkage applied to the coefficients. This leads to more coefficients being exactly zero, effectively performing feature selection and simplifying the model.\n",
        "Decreasing 位 reduces the regularization strength, allowing more coefficients to remain non-zero. This may lead to a more complex model that can potentially overfit the training data.\n",
        "Selection: 位 is typically selected using cross-validation techniques (such as k-fold cross-validation) or information criteria (like AIC or BIC). The goal is to choose a value that balances model complexity (number of non-zero coefficients) and predictive performance on unseen data.\n",
        "\n",
        "- Elastic Net Mixing Parameter ():\n",
        "\n",
        "Definition: 伪 (alpha) is a mixing parameter that controls the proportion of Ridge (L2) and Lasso (L1) penalties in Elastic Net regularization.\n",
        "\n",
        "Impact on Model Performance:\n",
        " allows for a flexible regularization approach between Ridge and Lasso Regression. A value of 伪=1 emphasizes sparsity and feature selection (like Lasso), while values closer to 0 balance Ridge-like shrinkage with some feature selection capabilities.\n",
        "Choosing 伪 involves considering the specific dataset characteristics, such as the level of multicollinearity and the desired model complexity.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9CHISqFaAE7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
      ],
      "metadata": {
        "id": "chly3HcaAFes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lasso Regression is inherently designed for linear regression tasks, it can be adapted for non-linear regression problems through feature engineering (e.g., polynomial features) or by integrating with kernel-based methods.\n",
        "These adaptations retain Lasso's regularization benefits, such as feature selection and model interpretability, making it a versatile choice for a wide range of regression tasks beyond linear relationships.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MCntZx-aAHW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What is the difference between Ridge Regression and Lasso Regression?"
      ],
      "metadata": {
        "id": "pwjE5oz5AIIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Ridge Regression and Lasso Regression are both regularization techniques used in linear regression to mitigate overfitting and improve model performance.\n",
        "While they share similarities in their regularization approaches, they differ primarily in how they apply penalties to the regression coefficients.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_LsKMHQZAJ6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
      ],
      "metadata": {
        "id": "RxiJ2PopAKWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lasso Regression does not directly handle multicollinearity like Ridge Regression, its feature selection mechanism can mitigate its effects by focusing on the most relevant predictors and shrinking less important predictors towards zero. This makes Lasso Regression a valuable tool in situations where interpretability and automatic variable selection are desired, even in the presence of multicollinearity.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aq8HNAdXAMEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
      ],
      "metadata": {
        "id": "FZ2CQUPrAMYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Choosing the optimal regularization parameter 位 in Lasso Regression involves balancing model complexity and predictive performance through cross-validation.\n",
        "This systematic approach helps ensure that the model generalizes well to new data and effectively handles feature selection and regularization in high-dimensional datasets.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aw2__ExXAN3F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}