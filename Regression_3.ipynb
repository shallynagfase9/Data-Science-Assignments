{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBfoIBkmAs92YoRnVHSihZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Data-Science-Assignments/blob/main/Regression_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
      ],
      "metadata": {
        "id": "in4GFaNQ9x3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Ridge Regression is a technique used in regression analysis to combat multicollinearity (high correlation between predictors) and overfitting.\n",
        "It extends Ordinary Least Squares (OLS) regression by adding a penalty term to the loss function that shrinks the coefficients towards zero.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KenrMOHI9z8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What are the assumptions of Ridge Regression?"
      ],
      "metadata": {
        "id": "Ths9XS1g90x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Here are the key assumptions of Ridge Regression:\n",
        "\n",
        "Linearity: Ridge Regression assumes that the relationship between the predictors (independent variables) and the dependent variable is linear. The model should capture the linear relationship adequately.\n",
        "Independence of Observations: Each observation in the dataset should be independent of the others.\n",
        "No Perfect Multicollinearity: Ridge Regression can handle multicollinearity (high correlation between predictors), but it assumes there is no perfect multicollinearity, where one predictor can be exactly predicted from others with perfect accuracy.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BBoP-hdi92vk",
        "outputId": "028e4577-461a-45e7-ac2b-fc9a3f5fbc9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nHere are the key assumptions of Ridge Regression:\\n\\nLinearity: Ridge Regression assumes that the relationship between the predictors (independent variables) and the dependent variable is linear. The model should capture the linear relationship adequately.\\nIndependence of Observations: Each observation in the dataset should be independent of the others. \\nNo Perfect Multicollinearity: Ridge Regression can handle multicollinearity (high correlation between predictors), but it assumes there is no perfect multicollinearity, where one predictor can be exactly predicted from others with perfect accuracy.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
      ],
      "metadata": {
        "id": "y833_aGU93Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Selecting the value of the tuning parameter (λ) in Ridge Regression is a critical step to ensure optimal model performance. The value of λ controls the strength of regularization: higher values of λ result in more shrinkage of coefficients, reducing variance but potentially increasing bias.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Lx6CpnmV95Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Can Ridge Regression be used for feature selection? If yes, how?"
      ],
      "metadata": {
        "id": "pFIMUvJ_95wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Yes, Ridge Regression can be used for feature selection, although it does not perform feature selection as aggressively as Lasso Regression.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jAEgCkez97lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
      ],
      "metadata": {
        "id": "uevHTqD-9-Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Ridge Regression is particularly effective in handling multicollinearity, which is the situation where independent variables (predictors) in a regression model are highly correlated with each other.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sKSg5cwT9-9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
      ],
      "metadata": {
        "id": "w6P8EQpL9_kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Yes, Ridge Regression can handle both categorical and continuous independent variables, but there are considerations and preprocessing steps to ensure the model works effectively with categorical variables.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vHT8QsXR-BVV",
        "outputId": "a35399be-a881-4648-bdee-dc7a98ea8bbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYes, Ridge Regression can handle both categorical and continuous independent variables, but there are considerations and preprocessing steps to ensure the model works effectively with categorical variables.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How do you interpret the coefficients of Ridge Regression?"
      ],
      "metadata": {
        "id": "asjsY1Uk-BsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Interpreting Ridge Regression coefficients involves considering both the direction (sign) and magnitude of coefficients, understanding how regularization affects their size, and interpreting them in the context of the model’s objective and predictor relationships.\n",
        "Standardization of predictors and careful comparison across models with different regularization strengths can enhance the interpretability and reliability of Ridge Regression coefficients in practical applications.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0VOZT6Ei-EA3",
        "outputId": "9430e0c7-a006-4c6f-c09b-eece98bb08a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nInterpreting Ridge Regression coefficients involves considering both the direction (sign) and magnitude of coefficients, understanding how regularization affects their size, and interpreting them in the context of the model’s objective and predictor relationships. \\nStandardization of predictors and careful comparison across models with different regularization strengths can enhance the interpretability and reliability of Ridge Regression coefficients in practical applications.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
      ],
      "metadata": {
        "id": "yfhx-iDm-EX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Yes, Ridge Regression can be adapted for time-series data analysis, but its direct application requires careful consideration and modifications to suit the temporal nature of the data.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "od3OyHAc-GIv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}