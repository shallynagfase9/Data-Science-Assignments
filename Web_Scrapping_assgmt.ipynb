{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRermRPYYXpwnITni9jt6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Data-Science-Assignments/blob/main/Web_Scrapping_assgmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL5OXwmr00aR"
      },
      "outputs": [],
      "source": [
        "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
        "'''\n",
        "Web scraping is the practice of automatically collecting large quantities of data from websites.\n",
        "\n",
        "Three primary areas where web scraping is commonly employed include:\n",
        "1) Lead Generation: Web scraping can be used to gather contact information for prospective customers or clients from various sources,\n",
        "such as business directories or social media platforms.\n",
        "2) Price Comparison and Competitive Monitoring: Businesses often utilize web scraping to track competitors' prices, product descriptions, and availability,\n",
        "allowing them to adjust their strategies accordingly.\n",
        "3) Data Analysis: Web scraping enables organizations to acquire vast datasets for analysis purposes, helping them identify patterns, trends, and opportunities.\n",
        "\n",
        "Additional applications of web scraping include market research, news monitoring, sentiment analysis, and real estate listing scraping\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. What are the different methods used for Web Scraping?\n",
        "'''\n",
        "In data science, web scraping involves various approaches to extract data from websites.\n",
        "\n",
        "Some of the key methods used for web scraping include:\n",
        "1. Manual Copy-and-Paste\n",
        "Directly copying and pasting data from a web page into a text file or spreadsheet.\n",
        "2. Text Pattern Matching\n",
        "Utilizing tools like grep or regular expressions to search for specific patterns and extract data.\n",
        "3. HTTP Programming\n",
        "Making HTTP requests to retrieve static and dynamic web pages.\n",
        "4. HTML Parsing\n",
        "Extracting data from HTML documents using libraries like BeautifulSoup or Scrapy.\n",
        "5. DOM Parsing\n",
        "Analyzing the Document Object Model (DOM) structure of a webpage to extract data.\n",
        "\n",
        "For data scientists, web scraping allows them to collect large amounts of data from diverse sources,\n",
        "enabling them to conduct advanced analyses and gain valuable insights.\n",
        "'''"
      ],
      "metadata": {
        "id": "uVL6yRHo1glI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. What is Beautiful Soup? Why is it used?\n",
        "'''\n",
        "Beautiful Soup is a Python library used for web scraping, which involves extracting data from websites.\n",
        "It simplifies the process of scraping information from web pages by sitting atop an HTML or XML parser and\n",
        "providing Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
        "'''"
      ],
      "metadata": {
        "id": "d6VLCbaC2R7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. Why is flask used in this Web Scraping project?\n",
        "'''\n",
        "Flask simplifies the process of setting up a web server that can trigger scraping scripts, making it easier to manage\n",
        "the flow of data extraction and processing in a web scraping project.\n",
        "Additionally, Flask's support for different HTTP methods like GET, POST, PUT, and DELETE allows developers to handle various types of requests efficiently.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "ubJTs6ph21qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
        "'''\n",
        "These services play crucial roles in the web scraping project:\n",
        "\n",
        "1. AWS Lambda handles the execution of web scraping scripts without the need to manage servers, ensuring scalability and cost-effectiveness\n",
        "\n",
        "2. Amazon S3 provides a reliable storage solution for the scraped data, allowing easy access and management of structured information generated from web scraping activities\n",
        "\n",
        "3. AWS Batch facilitates the running of jobs in a compute environment, enabling efficient execution of web scraping tasks based on predefined configurations, contributing to scalability and performance in handling large-scale scraping operations\n",
        "'''"
      ],
      "metadata": {
        "id": "3Pl39iXU3QD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}