{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr36ZWQia2xynnTF/Yjefm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Data-Science-Assignments/blob/main/Feature_Engineering_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4812yVukkR9"
      },
      "outputs": [],
      "source": [
        "# Q1. What is the Filter method in feature selection, and how does it work?\n",
        "\"\"\"\n",
        "The Filter method in feature selection is a simple and efficient technique to identify relevant features based on their statistical properties and correlation with the target variable.\n",
        "\n",
        "Working Steps in the Filter Method:\n",
        "- Feature Ranking: Calculate a statistical metric (e.g., correlation, mutual information, chi-square) for each feature with respect to the target variable. This metric assesses the relevance of each feature to the target variable.\n",
        "- Selecting Features: Rank the features based on their scores from the statistical metric. Higher scores indicate higher relevance or importance.\n",
        "- Thresholding: Optionally, set a threshold to select the top-ranked features. Features above this threshold are retained, while those below it are discarded.\n",
        "- Subset Selection: Create a subset of the dataset containing only the selected features for further analysis or modeling.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
        "\"\"\"\n",
        "The Wrapper method differs from the Filter method in feature selection primarily in how it evaluates features. While the Filter method assesses each feature independently of any machine learning algorithm,\n",
        "the Wrapper method incorporates the machine learning model directly into the feature selection process.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "mDmQ-RCXlGqI",
        "outputId": "d4263c19-75df-454f-d665-d7634fd9aff0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Wrapper method differs from the Filter method in feature selection primarily in how it evaluates features. While the Filter method assesses each feature independently of any machine learning algorithm, \\nthe Wrapper method incorporates the machine learning model directly into the feature selection process.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. What are some common techniques used in Embedded feature selection methods?\n",
        "\"\"\"\n",
        "Embedded feature selection methods, such as Lasso regression(L1 Regularization), Ridge regression(L2 Regularization), decision trees, random forests, and gradient boosting machines,\n",
        "are powerful techniques for selecting relevant features directly within the model training process.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "IOjKqWvRldYD",
        "outputId": "a916227d-ebd3-44d3-b64b-20da4167f666"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nEmbedded feature selection methods, such as Lasso regression(L1 Regularization), Ridge regression(L2 Regularization), decision trees, random forests, and gradient boosting machines, \\nare powerful techniques for selecting relevant features directly within the model training process. \\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. What are some drawbacks of using the Filter method for feature selection?\n",
        "\"\"\"\n",
        "Drawbacks:\n",
        "- independence assumption\n",
        "- Limited predictive power\n",
        "- Feature Redundancy\n",
        "- Loss of Information\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-DsHGp4PmAft",
        "outputId": "41236879-2187-48e7-8f7a-fcb40a539af9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDrawbacks:\\n- independence assumption\\n- Limited predictive power\\n- Feature Redundancy\\n- Loss of Information\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
        "\"\"\"\n",
        "The Filter method is preferred over the Wrapper method in situations where computational efficiency, simplicity, independence of features, preprocessing requirements,\n",
        "exploratory analysis, and interpretability are prioritized. However, it is essential to consider the limitations of the Filter method and evaluate its suitability based\n",
        "on the specific characteristics and goals of the modeling task.\n",
        "\n",
        "\"\"'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jk1-wAu7mdDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.\n",
        "You are unsure of which features to include in the model because the dataset contains several different\n",
        "ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "# Load the dataset\n",
        "data = pd.read_csv('telecom_dataset.csv')\n",
        "# Assuming 'churn' is the target variable and other columns are features\n",
        "X = data.drop('churn', axis=1)  # Features\n",
        "y = data['churn']  # Target variable\n",
        "\n",
        "# Calculate correlation coefficients for numerical features\n",
        "correlation_matrix = X.corrwith(y)\n",
        "\n",
        "# Calculate chi-square statistics for categorical features\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "chi2_stats = []\n",
        "for column in X.select_dtypes(include='object'):\n",
        "    contingency_table = pd.crosstab(X[column], y)\n",
        "    chi2, _, _, _ = chi2_contingency(contingency_table)\n",
        "    chi2_stats.append((column, chi2))\n",
        "\n",
        "# Sort features by relevance scores\n",
        "correlation_ranking = correlation_matrix.abs().sort_values(ascending=False)\n",
        "chi2_ranking = sorted(chi2_stats, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Choose top-n features based on the rankings or threshold\n",
        "top_n_features = correlation_ranking.index[:5].tolist()  # Select top 5 features based on correlation\n",
        "\n",
        "# Subset the dataset with selected features\n",
        "X_selected = X[top_n_features]\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "BXOacOmNmvUQ",
        "outputId": "65b18377-6f73-48e2-e672-51af2d2b94f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport pandas as pd\\nimport seaborn as sns\\n# Load the dataset\\ndata = pd.read_csv('telecom_dataset.csv')\\n# Assuming 'churn' is the target variable and other columns are features\\nX = data.drop('churn', axis=1)  # Features\\ny = data['churn']  # Target variable\\n\\n# Calculate correlation coefficients for numerical features\\ncorrelation_matrix = X.corrwith(y)\\n\\n# Calculate chi-square statistics for categorical features\\nfrom scipy.stats import chi2_contingency\\n\\nchi2_stats = []\\nfor column in X.select_dtypes(include='object'):\\n    contingency_table = pd.crosstab(X[column], y)\\n    chi2, _, _, _ = chi2_contingency(contingency_table)\\n    chi2_stats.append((column, chi2))\\n\\n# Sort features by relevance scores\\ncorrelation_ranking = correlation_matrix.abs().sort_values(ascending=False)\\nchi2_ranking = sorted(chi2_stats, key=lambda x: x[1], reverse=True)\\n\\n# Choose top-n features based on the rankings or threshold\\ntop_n_features = correlation_ranking.index[:5].tolist()  # Select top 5 features based on correlation\\n\\n# Subset the dataset with selected features\\nX_selected = X[top_n_features]\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with\n",
        "many features, including player statistics and team rankings. Explain how you would use the Embedded\n",
        "method to select the most relevant features for the model.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assuming X is your feature matrix and y is your target variable\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Assess feature importance\n",
        "feature_importance = model.feature_importances_\n",
        "sorted_indices = feature_importance.argsort()[::-1]\n",
        "\n",
        "# Select the top-n most important features\n",
        "top_n_features = X.columns[sorted_indices[:10]]  # Select top 10 features\n",
        "\n",
        "# Subset the dataset with selected features\n",
        "X_selected = X[top_n_features]\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "hvoXls9ingyt",
        "outputId": "c538f33b-92ee-4ed4-e78a-2014e791db8f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Assuming X is your feature matrix and y is your target variable\\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\\nmodel.fit(X, y)\\n\\n# Assess feature importance\\nfeature_importance = model.feature_importances_\\nsorted_indices = feature_importance.argsort()[::-1]\\n\\n# Select the top-n most important features\\ntop_n_features = X.columns[sorted_indices[:10]]  # Select top 10 features\\n\\n# Subset the dataset with selected features\\nX_selected = X[top_n_features]\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Q8. You are working on a project to predict the price of a house based on its features, such as size, location,\n",
        "and age. You have a limited number of features, and you want to ensure that you select the most important\n",
        "ones for the model. Explain how you would use the Wrapper method to select the best set of features for the\n",
        "predictor.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Choose a Suitable Machine Learning Model\n",
        "# 2. Define the Evaluation Metric\n",
        "# 3. Select a Feature Selection Technique\n",
        "# 4. Split the Dataset\n",
        "# 5. Train the Model with Feature Selection\n",
        "# 6. Evaluate Performance\n",
        "# 7. Determine Stopping Criterion\n",
        "# 8. Validate and Refine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "UCuLVp0AnH7d",
        "outputId": "a36bac56-566a-4099-e30d-2c0b61927195"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQ8. You are working on a project to predict the price of a house based on its features, such as size, location,\\nand age. You have a limited number of features, and you want to ensure that you select the most important\\nones for the model. Explain how you would use the Wrapper method to select the best set of features for the\\npredictor.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nuyEAcKil-rZ"
      }
    }
  ]
}